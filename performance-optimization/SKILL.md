---
name: "パフォーマンス最適化"
description: "パフォーマンス改善時の思考プロセス。最適化、高速化、パフォーマンス、速度改善に関する依頼に対応"
---

# パフォーマンス最適化: パフォーマンス改善時の思考プロセス

## このスキルを使う場面

- 速度・メモリ使用量の改善が目的
- ボトルネックの特定が必要
- レスポンスタイムが遅い
- スループットが低い
- リソース使用量が多い
- スケーラビリティの問題

## 思考プロセス

### フェーズ1: 計測と問題の特定

**基本原則: 計測が先、最適化は後**

- 推測で最適化しない
- 必ず計測してから改善
- データに基づく意思決定

**ステップ1: 現状の計測**

最適化前に必ず現状を計測：

**1. パフォーマンス指標の定義**

何を改善するか明確に：

- [ ] レスポンスタイム（秒・ミリ秒）
- [ ] スループット（リクエスト/秒）
- [ ] CPU 使用率（%）
- [ ] メモリ使用量（MB・GB）
- [ ] ディスク I/O
- [ ] ネットワーク帯域

**2. ベースライン測定**

最適化前の状態を記録：

- [ ] 平均値
- [ ] 中央値
- [ ] 95 パーセンタイル・99 パーセンタイル
- [ ] 最大値・最小値
- [ ] 標準偏差

**3. 目標の設定**

どこまで改善するか：

- [ ] 目標値を具体的に（例: レスポンスタイム 500ms 以下）
- [ ] 現実的な目標か確認
- [ ] 優先順位（レスポンスタイム vs スループット等）

**ステップ2: ボトルネックの特定**

**1. プロファイリング**

どこが遅いか特定：

**CPU プロファイリング:**

- どの関数が CPU を多く使っているか
- ホットスポット（頻繁に呼ばれる箇所）
- コールグラフ

**メモリプロファイリング:**

- どこでメモリを多く使っているか
- メモリリーク
- 不要なオブジェクトの保持

**I/O プロファイリング:**

- ディスク読み書きの頻度
- ネットワーク通信の回数
- データベースクエリの実行時間

**2. ボトルネックの分類**

**CPU バウンド:**

- 計算量の多い処理
- 複雑なアルゴリズム
- ループの多用

**I/O バウンド:**

- ディスク読み書き
- ネットワーク通信
- データベースアクセス

**メモリバウンド:**

- 大量のデータ
- メモリ不足
- スワップの発生

**3. 80/20 の法則**

- 80% の時間を 20% のコードが消費
- その 20% を特定して最適化
- すべてを最適化しようとしない

**移行条件:**

- [ ] 現状を計測した
- [ ] ボトルネックを特定した
- [ ] 目標を設定した

### フェーズ2: 最適化の優先順位と戦略

**ステップ1: 最適化の優先順位**

以下の順序で検討：

**1. アーキテクチャレベル（最優先）**

- キャッシュの導入
- 非同期処理
- 並列処理
- データベース設計の見直し
- API 設計の見直し

**効果が大きく、影響範囲も大きい**

**2. アルゴリズムレベル**

- より効率的なアルゴリズム
- データ構造の変更
- 計算量の削減（O(n²) → O(n log n)）

**効果が大きい**

**3. コードレベル**

- 不要な処理の削除
- ループの最適化
- 条件分岐の最適化

**効果は限定的だが、実装は簡単**

**4. 環境レベル**

- サーバースペックの向上
- ネットワークの改善
- ハードウェアの追加

**コストがかかるが、確実**

**ステップ2: 最適化戦略の選択**

**キャッシング戦略:**

キャッシュで I/O を削減：

1. **アプリケーションキャッシュ**
   - メモリ内キャッシュ
   - Redis/Memcached
   - 頻繁にアクセスされるデータ

2. **データベースクエリキャッシュ**
   - クエリ結果のキャッシュ
   - ORM のキャッシュ機能

3. **HTTP キャッシュ**
   - ブラウザキャッシュ
   - CDN
   - 静的コンテンツ

**キャッシュの注意点:**

- キャッシュの無効化戦略
- TTL（生存時間）の設定
- メモリ使用量とのトレードオフ

**非同期処理戦略:**

即座の応答が不要な処理を非同期化：

1. **バックグラウンドジョブ**
   - メール送信
   - レポート生成
   - データ集計

2. **メッセージキュー**
   - 処理の分散
   - ピーク対策
   - リトライ機能

3. **イベント駆動**
   - 疎結合
   - スケーラビリティ

**並列処理戦略:**

複数のタスクを同時実行：

1. **マルチスレッド**
   - CPU バウンドな処理
   - 注意: GIL（Python 等）

2. **マルチプロセス**
   - 完全な並列化
   - CPU コア数まで

3. **非同期 I/O**
   - I/O バウンドな処理
   - async/await

**データベース最適化戦略:**

データベースアクセスを最適化：

1. **インデックス**
   - 頻繁に検索する列
   - 複合インデックス
   - カバリングインデックス

2. **クエリ最適化**
   - N+1 問題の解決
   - JOIN の最適化
   - 不要な列の削除（SELECT *）

3. **接続プーリング**
   - 接続の再利用
   - 接続コストの削減

**移行条件:**

- [ ] 最適化の優先順位を決定した
- [ ] 戦略を選択した
- [ ] 実装計画を立てた

### フェーズ3: 最適化の実装

**ステップ1: 一つずつ実装・計測**

**基本サイクル:**

1. **一つの最適化を実装**
2. **計測**
3. **効果を確認**
4. **コミット**
5. **次へ**

**重要: 複数の最適化を同時にしない**

- どれが効果的か分からなくなる
- 問題が起きた時の切り分けが困難
- 一つずつ確実に

**ステップ2: アーキテクチャレベルの最適化**

**例1: キャッシュの導入**

```python
# Before
def get_user_posts(user_id):
    return database.query("SELECT * FROM posts WHERE user_id = ?", user_id)

# After
def get_user_posts(user_id):
    cache_key = f"user_posts:{user_id}"
    cached = cache.get(cache_key)
    if cached:
        return cached

    posts = database.query("SELECT * FROM posts WHERE user_id = ?", user_id)
    cache.set(cache_key, posts, ttl=300)  # 5分間キャッシュ
    return posts
```

**計測:**

- キャッシュヒット率
- レスポンスタイムの改善
- データベース負荷の削減

**例2: 非同期処理**

```python
# Before
def create_order(order_data):
    order = save_order(order_data)
    send_confirmation_email(order)  # 遅い
    update_inventory(order)  # 遅い
    return order

# After
def create_order(order_data):
    order = save_order(order_data)
    # 非同期タスクとして実行
    async_task.send_confirmation_email.delay(order.id)
    async_task.update_inventory.delay(order.id)
    return order
```

**計測:**

- レスポンスタイムの改善
- スループットの向上

**ステップ3: アルゴリズムレベルの最適化**

**例: アルゴリズムの改善**

```python
# Before: O(n²)
def find_duplicates(items):
    duplicates = []
    for i, item1 in enumerate(items):
        for j, item2 in enumerate(items):
            if i != j and item1 == item2:
                duplicates.append(item1)
    return duplicates

# After: O(n)
def find_duplicates(items):
    seen = set()
    duplicates = set()
    for item in items:
        if item in seen:
            duplicates.add(item)
        seen.add(item)
    return list(duplicates)
```

**計測:**

- 実行時間の比較
- 大量データでのテスト

**例: データ構造の変更**

```python
# Before: リストで線形探索 O(n)
user_ids = [1, 2, 3, 4, 5, ...]
if user_id in user_ids:  # 遅い
    ...

# After: セットでハッシュ探索 O(1)
user_ids = {1, 2, 3, 4, 5, ...}
if user_id in user_ids:  # 速い
    ...
```

**ステップ4: コードレベルの最適化**

**例1: 不要な処理の削除**

```python
# Before
def process_users(users):
    results = []
    for user in users:
        # ループ内で毎回計算（不要）
        threshold = calculate_threshold()
        if user.score > threshold:
            results.append(user)
    return results

# After
def process_users(users):
    results = []
    threshold = calculate_threshold()  # 一度だけ計算
    for user in users:
        if user.score > threshold:
            results.append(user)
    return results
```

**例2: ループの最適化**

```python
# Before
result = []
for item in items:
    result.append(item.value * 2)

# After: リスト内包表記（Python では高速）
result = [item.value * 2 for item in items]
```

**例3: 早期リターン**

```python
# Before
def find_user(user_id):
    users = get_all_users()  # すべてのユーザーを取得
    for user in users:
        if user.id == user_id:
            return user
    return None

# After
def find_user(user_id):
    # 直接データベースで検索
    return database.query("SELECT * FROM users WHERE id = ?", user_id)
```

**移行条件:**

- [ ] 最適化を実装した
- [ ] 効果を計測した
- [ ] 目標を達成した、または次の最適化へ

### フェーズ4: 検証とモニタリング

**ステップ1: 改善効果の検証**

**1. ベースラインとの比較**

- 最適化前 vs 最適化後
- 具体的な数値で比較
- パーセンテージでの改善率

**2. 目標達成の確認**

- [ ] 目標値を達成したか
- [ ] すべての指標で改善したか
- [ ] 新しい問題は起きていないか

**3. 副作用の確認**

- [ ] 機能が正しく動作するか
- [ ] 他の部分に悪影響がないか
- [ ] メモリ使用量は増えていないか
- [ ] コードの可読性は保たれているか

**ステップ2: 負荷テスト**

実際の負荷でテスト：

**1. 負荷パターン**

- 通常時の負荷
- ピーク時の負荷
- 徐々に増加する負荷
- 突然増加する負荷

**2. 計測項目**

- レスポンスタイム（平均・パーセンタイル）
- エラー率
- スループット
- リソース使用量

**3. ボトルネックの再確認**

- 新しいボトルネックが出現していないか
- さらなる最適化の余地

**ステップ3: 継続的なモニタリング**

本番環境で監視：

**1. メトリクスの収集**

- APM（Application Performance Monitoring）
- ログ
- メトリクスダッシュボード

**2. アラートの設定**

- しきい値の設定
- 異常検知
- 自動通知

**3. 定期的なレビュー**

- パフォーマンスの推移
- 新しいボトルネックの発見
- 継続的な改善

**移行条件:**

- [ ] 改善効果を検証した
- [ ] 負荷テストを実施した
- [ ] モニタリングを設定した

## 判断のポイント

### いつ最適化すべきか

**すぐに最適化:**

- ユーザー体験に明らかな問題
- SLA 違反
- コスト増大
- スケールの限界

**後で最適化:**

- まだ問題になっていない
- ユーザー数が少ない
- 他の優先タスクがある

**最適化しない:**

- 改善の余地が小さい
- コストがメリットを上回る
- プロトタイプ・PoC

### どこまで最適化すべきか

**十分な最適化:**

- 目標を達成した
- ユーザーが満足している
- コストパフォーマンスが良い

**さらなる最適化:**

- まだボトルネックがある
- 将来の成長を見越して
- 競合優位性のため

**過剰な最適化:**

- マイクロ秒レベルの改善
- コードの可読性を大きく損なう
- 保守性が著しく低下

## よくある落とし穴

1. **計測せずに最適化**
   - ❌ 推測で最適化
   - ✅ 必ず計測してから

2. **早すぎる最適化**
   - ❌ 問題が起きる前から最適化
   - ✅ 本当に必要になってから

3. **複数の最適化を同時に**
   - ❌ いろいろ試して何が効いたか不明
   - ✅ 一つずつ実装・計測

4. **可読性の犠牲**
   - ❌ 速度のために分かりにくいコード
   - ✅ バランスを取る

5. **局所最適化**
   - ❌ 細部にこだわる
   - ✅ 全体のボトルネックを解決

6. **副作用の無視**
   - ❌ 速度だけ見る
   - ✅ メモリ・可読性も考慮

7. **ハードウェアで解決**
   - ❌ すぐにスペックアップ
   - ✅ まずソフトウェアで改善

## 検証ポイント

### 計測の検証

- [ ] ベースラインを測定した
- [ ] ボトルネックを特定した
- [ ] 目標を設定した
- [ ] 計測方法が適切

### 最適化の検証

- [ ] 一つずつ実装した
- [ ] 各ステップで計測した
- [ ] 効果を確認した
- [ ] 副作用がない

### 完了の検証

- [ ] 目標を達成した
- [ ] 負荷テストを実施した
- [ ] モニタリングを設定した
- [ ] ドキュメントを更新した

## 他スキルとの連携

### performance-optimization → debugging

パフォーマンス問題の原因特定：

1. このスキルでボトルネックを特定
2. debugging スキルで根本原因を分析
3. 適切な最適化方法を決定

### performance-optimization → data-analysis

パフォーマンスデータの分析：

1. このスキルでメトリクスを収集
2. data-analysis スキルでパターン分析
3. 傾向・予測に基づく最適化

### performance-optimization + system-design

アーキテクチャレベルの最適化：

1. このスキルでボトルネックを特定
2. system-design スキルでアーキテクチャを再設計
3. スケーラブルな構造に変更

### performance-optimization → code-review

最適化コードのレビュー：

1. このスキルで最適化を実装
2. code-review スキルで品質確認
3. 可読性とのバランスを検証

## パフォーマンス最適化のベストプラクティス

### 計測が第一

- 推測しない
- データに基づく
- 継続的に計測

### 80/20 の法則

- 20% のコードが 80% の時間を消費
- そこを最適化する
- すべてを最適化しない

### 段階的な改善

- 小さく改善
- 効果を確認
- 繰り返す

### バランスを取る

- 速度 vs 可読性
- 速度 vs メモリ
- 速度 vs 保守性
- コストパフォーマンス
